{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTxWP6X_zv17"
      },
      "source": [
        "# SVHN Dataset - Original Images\n",
        "\n",
        "#### Preprocessing of the original images from the SVHN dataset\n",
        "\n",
        "---\n",
        "\n",
        "This notebook describes my approach to load and preprocess the original images from the SVHN dataset. The dataset consists of variable-resolution images with character level bounding boxes. I have used this notebook to create both 32 x 32 pixel images and 64 x 64 pixel images. As a general note the input layer (that contains the image) should be divisible by 2 many times. Common numbers include 32 (e.g. CIFAR-10), 64, 96 (e.g. STL-10), or 224 (e.g. common ImageNet ConvNets), 384, and 512.\n",
        "\n",
        "#### Preprocessing steps:\n",
        "\n",
        "1. One street view image contains more than five digits and is removed. This means that our model assumes that the sequence length is at most 5\n",
        "2. We crop the images by finding the bounding boxes of each individual character, expand this box by 30% in the x and y direction and crop the image to that bounding box and resize the crop to 64x64\n",
        "3. Convert the images to greyscale\n",
        "\n",
        "The [original paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf) mentions cropping 54x54 images from random locations within the 64 x 64 pixels in order to increase the size of the dataset. Due to limited time we will not experiment with data augmentation in order to improve performance. In case I choose to implement data augmentation at a later point this will be implemented using TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-DUOHh30zv1_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.display import display, Image, HTML\n",
        "import h5py\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16.0, 4.0)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vehlwHmzv2B",
        "outputId": "20483d7c-0302-40ce-c0f1-0133f360db2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0.tar.gz (15.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: scipy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for scipy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scipy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for scipy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py clean\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for scipy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build scipy\n",
            "\u001b[31mERROR: Could not build wheels for scipy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install scipy==1.1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb6cfS-6zv2D",
        "outputId": "ab36fc96-1390-4e55-cb44-d801ef5dcf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.22.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (8.4.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n"
          ]
        }
      ],
      "source": [
        "pip install imageio scikit-image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPF52fMzzv2E"
      },
      "source": [
        "### Downloading the datasets\n",
        "\n",
        "Let's start off by downloading the data from <a href=\"http://ufldl.stanford.edu/housenumbers/\">this page</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "yCN1idFnzv2E"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "#urllib.request.urlretrieve(\"http://ufldl.stanford.edu/housenumbers/train.tar.gz\", \"data/train.tar.gz\")\n",
        "#urllib.request.urlretrieve(\"http://ufldl.stanford.edu/housenumbers/test.tar.gz\", \"data/test.tar.gz\")\n",
        "#urllib.request.urlretrieve(\"http://ufldl.stanford.edu/housenumbers/extra.tar.gz\", \"data/extra.tar.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnbbl0Fjzv2F"
      },
      "source": [
        "After downloading the datasets we need to extract the tarballs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "aOI-Em62zv2F",
        "outputId": "a10402ba-496f-4840-ddf3-efb09cd494a3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c506b526a047>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Get the directory listing for the dataset folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mls_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'tar.gz'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# cd data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
          ]
        }
      ],
      "source": [
        "def extract_tarball(filename, force=False):\n",
        "    \"\"\" Helper function for extracting tarball files\n",
        "    \"\"\"\n",
        "    # Drop the file extension\n",
        "    root = filename.split('.')[0] \n",
        "    \n",
        "    # If file is already extracted - return\n",
        "    if os.path.isdir(root) and not force:\n",
        "        print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
        "        return\n",
        "    \n",
        "    # If file is a tarball file - extract it\n",
        "    if (filename.endswith(\"tar.gz\")):\n",
        "        print(\"Extracting %s ...\" % filename)\n",
        "        tar = tarfile.open(filename, \"r:gz\")\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "        \n",
        "        \n",
        "# Get the directory listing for the dataset folder\n",
        "ls_data = [f for f in os.listdir(\"data\") if 'tar.gz' in f]\n",
        "        \n",
        "# cd data\n",
        "os.chdir(\"data\")\n",
        "\n",
        "# Extract the tarballs\n",
        "#extract_tarball(ls_data[0])\n",
        "extract_tarball(ls_data[1])\n",
        "#extract_tarball(ls_data[2])\n",
        "    \n",
        "# cd ..\n",
        "os.chdir(os.path.pardir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcu-mNrGzv2G"
      },
      "source": [
        "### Bounding boxes\n",
        "\n",
        "The code for unwrapping the digitStruct files can be found in *unpacker.py*. The digitStruct files contains our labels and information on our bounding boxes which are central to our cropping procedure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30dR7xK_zv2G"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "\n",
        "class DigitStructWrapper:\n",
        "    \"\"\"\n",
        "    Wrapper for the H5PY digitStruct files from the SVHN dataset\n",
        "\n",
        "    Creates an array of dictionaries containing the filename and bounding boxes for every digit in the image.\n",
        "\n",
        "    Adapted from https://github.com/hangyao\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, inf):\n",
        "        self.inf = h5py.File(inf, 'r')\n",
        "        self.digitStructName = self.inf['digitStruct']['name']\n",
        "        self.digitStructBbox = self.inf['digitStruct']['bbox']\n",
        "\n",
        "    def get_name(self, n):\n",
        "        \"\"\"Return the name of the n(th) digit struct\"\"\"\n",
        "        return ''.join([chr(c[0]) for c in self.inf[self.digitStructName[n][0]][()]])\n",
        "\n",
        "    def get_attribute(self, attr):\n",
        "        \"\"\"Helper function for dealing with one vs. multiple bounding boxes\"\"\"\n",
        "        if (len(attr) > 1):\n",
        "            attr = [self.inf[attr[()][j].item()][()][0][0] for j in range(len(attr))]\n",
        "        else:\n",
        "            attr = [attr[()][0][0]]\n",
        "        return attr\n",
        "\n",
        "    def get_bbox(self, n):\n",
        "        \"\"\"Return a dict containing the data from the n(th) bbox\"\"\"\n",
        "        bbox = {}\n",
        "        bb = self.digitStructBbox[n].item()\n",
        "        bbox['height'] = self.get_attribute(self.inf[bb][\"height\"])\n",
        "        bbox['label'] = self.get_attribute(self.inf[bb][\"label\"])\n",
        "        bbox['left'] = self.get_attribute(self.inf[bb][\"left\"])\n",
        "        bbox['top'] = self.get_attribute(self.inf[bb][\"top\"])\n",
        "        bbox['width'] = self.get_attribute(self.inf[bb][\"width\"])\n",
        "        return bbox\n",
        "\n",
        "    def get_item(self, n):\n",
        "        \"\"\"Return the name and bounding boxes of a single image\"\"\"\n",
        "        s = self.get_bbox(n)\n",
        "        s['name'] = self.get_name(n)\n",
        "        return s\n",
        "\n",
        "    def unpack(self):\n",
        "        \"\"\"Returns a list of dicts containing all the bounding boxes\"\"\"\n",
        "        return [self.get_item(i) for i in range(len(self.digitStructName))]\n",
        "\n",
        "    def unpack_all(self):\n",
        "        pictDat = self.unpack()\n",
        "        result = []\n",
        "        structCnt = 1\n",
        "        for i in range(len(pictDat)):\n",
        "            item = {'filename': pictDat[i][\"name\"]}\n",
        "            figures = []\n",
        "            for j in range(len(pictDat[i]['height'])):\n",
        "                figure = {}\n",
        "                figure['height'] = pictDat[i]['height'][j]\n",
        "                figure['label'] = pictDat[i]['label'][j]\n",
        "                figure['left'] = pictDat[i]['left'][j]\n",
        "                figure['top'] = pictDat[i]['top'][j]\n",
        "                figure['width'] = pictDat[i]['width'][j]\n",
        "                figures.append(figure)\n",
        "            structCnt = structCnt + 1\n",
        "            item['boxes'] = figures\n",
        "            result.append(item)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HfVM-cKgzv2H"
      },
      "outputs": [],
      "source": [
        "#from unpacker import DigitStructWrapper\n",
        "\n",
        "def get_bounding_boxes(start_path = '.'):\n",
        "    \"\"\" Extracts a bounding box file and returns a dictionary\n",
        "    \"\"\"\n",
        "    return DigitStructWrapper(start_path).unpack_all()\n",
        "\n",
        "# Extract the bounding boxes (this will take a while!)\n",
        "train_bbox = get_bounding_boxes('data/train/digitStruct.mat')\n",
        "test_bbox = get_bounding_boxes('data/test/digitStruct.mat')\n",
        "#extra_bbox = get_bounding_boxes('data/extra/digitStruct.mat')\n",
        "\n",
        "# Display the information stored about an individual image\n",
        "print(json.dumps(train_bbox[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2eB6-s5zv2H"
      },
      "outputs": [],
      "source": [
        "print(json.dumps(train_bbox[0], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzYr9ViGzv2I"
      },
      "source": [
        "To better understand how the bounding box relates to the images i have written a simple function that displays the image and overlays each bounding box as rectangle with blue edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HGuqYRNRzv2I"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def display_bounding_boxes(img, bounding_boxes):\n",
        "    \"\"\"Displays an image and overlays the bounding boxes\n",
        "    \"\"\"\n",
        "    # Opens and identifies the given image file\n",
        "    image = Image.open(img)\n",
        "    \n",
        "    # Use draw module can be used to annotate the image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    \n",
        "    for b in bounding_boxes:\n",
        "        \n",
        "        # Bounding box rectangle [x0, y0, x1, y1]\n",
        "        rectangle = [b['left'], b['top'], b['left'] + b['width'], b['top'] + b['height']]\n",
        "        \n",
        "        # Draw a rectangle on top of the image\n",
        "        draw.rectangle(rectangle, outline=\"blue\")\n",
        "        \n",
        "    # Return altered image    \n",
        "    return image\n",
        "\n",
        "\n",
        "# Select an image and the corresponding boxes\n",
        "image = 'data/train/1.png'\n",
        "image_bounding_boxes = train_bbox[0]['boxes']\n",
        "     \n",
        "# Display image with bounding boxes\n",
        "display_bounding_boxes(image, image_bounding_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi61Qur6zv2J"
      },
      "source": [
        "To be able to more easily work with the bounding box data, let's move it into a DataFrame to simplify the process of calculating our crops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4wwAqQsszv2K"
      },
      "outputs": [],
      "source": [
        "def dict_to_dataframe(image_bounding_boxes, path):\n",
        "    \"\"\" Helper function for flattening the bounding box dictionary\n",
        "    \"\"\"\n",
        "    # Store each bounding box\n",
        "    boxes = []\n",
        "    \n",
        "    # For each set of bounding boxes\n",
        "    for image in image_bounding_boxes:\n",
        "        \n",
        "        # For every bounding box\n",
        "        for bbox in image['boxes']:\n",
        "            \n",
        "            # Store a dict with the file and bounding box info\n",
        "            boxes.append({\n",
        "                    'filename': path + image['filename'],\n",
        "                    'label': bbox['label'],\n",
        "                    'width': bbox['width'],\n",
        "                    'height': bbox['height'],\n",
        "                    'top': bbox['top'],\n",
        "                    'left': bbox['left']})\n",
        "            \n",
        "    # return the data as a DataFrame\n",
        "    return pd.DataFrame(boxes)\n",
        "\n",
        "\n",
        "# We store the bounding boxes here\n",
        "bbox_file = 'data/bounding_boxes.csv'\n",
        "\n",
        "if not os.path.isfile(bbox_file):\n",
        "    \n",
        "    # Extract every individual bounding box as DataFrame  \n",
        "    train_df = dict_to_dataframe(train_bbox, 'data/train/')\n",
        "    test_df = dict_to_dataframe(test_bbox, 'data/test/')\n",
        "    #extra_df = dict_to_dataframe(extra_bbox, 'data/extra/')\n",
        "\n",
        "    print(\"Training\", train_df.shape)\n",
        "    print(\"Test\", test_df.shape)\n",
        "    #print(\"Extra\", extra_df.shape)\n",
        "    print('')\n",
        "\n",
        "    # Concatenate all the information in a single file\n",
        "    df = pd.concat([train_df, test_df])\n",
        "    \n",
        "    print(\"Combined\", df.shape)\n",
        "\n",
        "    # Write dataframe to csv\n",
        "    df.to_csv(bbox_file, index=False)\n",
        "\n",
        "    # Delete the old dataframes\n",
        "    del train_df, test_df, train_bbox, test_bbox\n",
        "    \n",
        "else:\n",
        "    # Load preprocessed bounding boxes\n",
        "    df = pd.read_csv(bbox_file)\n",
        "\n",
        "# Display the first 10 rows of dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVX1It_Tzv2L"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/bounding_boxes.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Nl9lb0zv2L"
      },
      "source": [
        "#### Grouping the images by image\n",
        "\n",
        "In our cropping procedure we expand the bounding box by 30% in the x and y direction and crop the image. We start by finding the digit sequence bounding box by taking the minimum (x0, y0) and maximum (x1, y1) of each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "RzYzV7xNzv2L"
      },
      "outputs": [],
      "source": [
        "# Rename the columns to more suitable names\n",
        "df.rename(columns={'left': 'x0', 'top': 'y0', 'label': 'labels'}, inplace=True)\n",
        "\n",
        "# Calculate x1 and y1\n",
        "df['x1'] = df['x0'] + df['width']\n",
        "df['y1'] = df['y0'] + df['height']\n",
        "\n",
        "# Perform the following aggregations\n",
        "aggregate = {'x0':'min',\n",
        "             'y0':'min',\n",
        "             'x1':'max',\n",
        "             'y1':'max',\n",
        "             'labels': lambda x: list(x)}\n",
        "\n",
        "# Apply the aggration\n",
        "df = df.groupby('filename').agg(aggregate).reset_index()\n",
        "df['num_digits'] = df['labels'].str.len()\n",
        "\n",
        "# Fix the column names after aggregation\n",
        "# df.columns = [x[0] if i < 5 else x[1] for i, x in enumerate(df.columns.values)]\n",
        "\n",
        "# Display the results\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeKja1Ixzv2M"
      },
      "source": [
        "Let's draw a new bounding box to verify that everything is still looking fine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2oJaTgRozv2M"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "def display_bbox(image_path, bbox):\n",
        "    \"\"\" Helper function to display a single image and bounding box\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    draw.rectangle([bbox['x0'], bbox['y0'], bbox['x1'], bbox['y1']], outline=\"blue\")\n",
        "    return image\n",
        "\n",
        "\n",
        "# Select a image and bounding box\n",
        "image = 'data/train/1.png'\n",
        "bbox = df[df.filename == image]\n",
        "\n",
        "# Display image\n",
        "display_bbox(image, bbox)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKLNs2l4zv2N"
      },
      "source": [
        "Let's expand our bounding boxes by 30% in both directions and use this as a basis for our cropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ToL5cZHtzv2N"
      },
      "outputs": [],
      "source": [
        "# Calculate the increase in both directions\n",
        "df['x_increase'] = ((df['x1'] - df['x0']) * 0.3) / 2.\n",
        "df['y_increase'] = ((df['y1'] - df['y0']) * 0.3) / 2.\n",
        "\n",
        "# Apply the increase in all four directions\n",
        "df['x0'] = (df['x0'] - df['x_increase']).astype('int')\n",
        "df['y0'] = (df['y0'] - df['y_increase']).astype('int')\n",
        "df['x1'] = (df['x1'] + df['x_increase']).astype('int')\n",
        "df['y1'] = (df['y1'] + df['y_increase']).astype('int')\n",
        "\n",
        "\n",
        "# Select the dataframe row corresponding to our image\n",
        "image = 'data/train/1.png'\n",
        "bbox = df[df.filename == image]\n",
        "\n",
        "# Display image\n",
        "display_bbox(image, bbox)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp2qQP7szv2N"
      },
      "source": [
        "### Image sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5ttAYL9zv2N"
      },
      "source": [
        "The digitStruct files did not contain any information on the file sizes of the images. Since this information could be relevant for our preprocessing, e.g. in case we want to remove low-quality images or improve our cropping procedure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "hZCmzxNzzv2O"
      },
      "outputs": [],
      "source": [
        "def get_image_size(filepath):\n",
        "    \"\"\"Returns the image size in pixels given as a 2-tuple (width, height)\n",
        "    \"\"\"\n",
        "    image = Image.open(filepath)\n",
        "    return image.size \n",
        "\n",
        "def get_image_sizes(folder):\n",
        "    \"\"\"Returns a DataFrame with the file name and size of all images contained in a folder\n",
        "    \"\"\"\n",
        "    image_sizes = []\n",
        "    \n",
        "    # Get all .png images contained in the folder\n",
        "    images = [img for img in os.listdir(folder) if img.endswith('.png')]\n",
        "    \n",
        "    # Get image size of every individual image\n",
        "    for image in images:\n",
        "        w, h = get_image_size(folder + image)\n",
        "        image_size = {'filename': folder + image, 'image_width': w, 'image_height': h}\n",
        "        image_sizes.append(image_size)\n",
        "        \n",
        "    # Return results as a pandas DataFrame\n",
        "    return pd.DataFrame(image_sizes)\n",
        "\n",
        "\n",
        "# Extract the image sizes\n",
        "train_sizes = get_image_sizes('data/train/')\n",
        "test_sizes = get_image_sizes('data/test/')\n",
        "#extra_sizes = get_image_sizes('data/extra/')\n",
        "\n",
        "# Concatenate all the information in a single file\n",
        "image_sizes = pd.concat([train_sizes, test_sizes])\n",
        "\n",
        "# Delete old dataframes\n",
        "del train_sizes, test_sizes\n",
        "\n",
        "# Display 10 image sizes\n",
        "image_sizes.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un0hAlc8zv2O"
      },
      "source": [
        "Let's merge the new data into our previously created dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "OJTOrGcuzv2P"
      },
      "outputs": [],
      "source": [
        "print(\"Bounding boxes\", df.shape)\n",
        "print(\"Image sizes\", image_sizes.shape)\n",
        "print('')\n",
        "\n",
        "# Inner join the datasets on filename\n",
        "df = pd.merge(df, image_sizes, on='filename', how='inner')\n",
        "\n",
        "print(\"Combined\", df.shape)\n",
        "\n",
        "# Delete the image size df\n",
        "del image_sizes\n",
        "\n",
        "# Store checkpoint\n",
        "df.to_csv(\"data/image_data.csv\", index=False)\n",
        "#df = pd.read_csv('data/image_data.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnxcA4ZDzv2P"
      },
      "source": [
        "We can now make some correction to the bounding boxes to make sure that they are contained by the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzKsRJ99zv2Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "r9PZBEJ9zv2Q"
      },
      "outputs": [],
      "source": [
        "# Correct bounding boxes not contained by image\n",
        "df.loc[df['x0'] < 0, 'x0'] = 0\n",
        "df.loc[df['y0'] < 0, 'y0'] = 0\n",
        "df.loc[df['x1'] > df['image_width'], 'x1'] = df['image_width']\n",
        "df.loc[df['y1'] > df['image_height'], 'y1'] = df['image_width']\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd0ZrOZUzv2Q"
      },
      "source": [
        "### Removing images with more than 5 digits\n",
        "\n",
        "We have one image with more than 5 digits, let's remove it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "gr1PwPEBzv2Q"
      },
      "outputs": [],
      "source": [
        "# Count the number of images by number of digits\n",
        "df.num_digits.value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "q5u4TJvGzv2R"
      },
      "outputs": [],
      "source": [
        "# Keep only images with less than 6 digits\n",
        "df = df[df.num_digits < 6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49nN8SItzv2S"
      },
      "source": [
        "### Low quality images\n",
        "\n",
        "We have some images in the dataset that are very, very small. We should verify that some of these images looks OK after cropping and scaling them to 64 x 64 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HstzmPXBzv2T"
      },
      "outputs": [],
      "source": [
        "df[['image_width', 'image_height']].describe().round(decimals=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKdd4Zyzv2U"
      },
      "source": [
        "### Cropping the images\n",
        "\n",
        "Let's crop our images using by using our expanded bounding boxes and reshape our labels into a more convenient format. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "GHuPAqRXzv2U"
      },
      "outputs": [],
      "source": [
        "### from scipy.ndimage import imread\n",
        "#from scipy.misc import imresize\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Read the image using imageio\n",
        "#image = imageio.imread('path/to/your/image.png')\n",
        "\n",
        "# Resize the image using skimage.transform.resize\n",
        "#resized_image = resize(image, (new_height, new_width))\n",
        "\n",
        "\n",
        "def crop_and_resize(image, img_size):\n",
        "    \"\"\" Crop and resize an image\n",
        "    \"\"\"\n",
        "    image_data = imageio.imread(image['filename'])\n",
        "    crop = image_data[image['y0']:image['y1'], image['x0']:image['x1'], :]\n",
        "    return resize(crop, img_size)\n",
        "\n",
        "\n",
        "def create_dataset(df, img_size):\n",
        "    \"\"\" Helper function for converting images into a numpy array\n",
        "    \"\"\"\n",
        "    # Initialize the numpy arrays (0's are stored as 10's)\n",
        "    X = np.zeros(shape=(df.shape[0], img_size[0], img_size[0], 3), dtype='float32')\n",
        "    y = np.full((df.shape[0], 5), 10, dtype=int)\n",
        "    \n",
        "    # Iterate over all images in the pandas dataframe (slow!)\n",
        "    for i, (index, image) in enumerate(df.iterrows()):\n",
        "        \n",
        "        # Get the image data\n",
        "        X[i] = crop_and_resize(image, img_size)\n",
        "        \n",
        "        # Get the label list as an array\n",
        "        labels = np.array((image['labels']))\n",
        "                \n",
        "        # Store 0's as 0 (not 10)\n",
        "        labels[labels==10] = 0\n",
        "        \n",
        "        # Embed labels into label array\n",
        "        y[i,0:labels.shape[0]] = labels\n",
        "        \n",
        "    # Return data and labels   \n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Change this to select a different image size\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Get cropped images and labels (this might take a while...)\n",
        "X_train, y_train = create_dataset(df[df.filename.str.contains('train')], image_size)\n",
        "X_test, y_test = create_dataset(df[df.filename.str.contains('test')], image_size)\n",
        "#X_extra, y_extra = create_dataset(df[df.filename.str.contains('extra')], image_size)\n",
        "\n",
        "# We no longer need the dataframe\n",
        "del df\n",
        "\n",
        "print(\"Training\", X_train.shape, y_train.shape)\n",
        "print(\"Test\", X_test.shape, y_test.shape)\n",
        "#print('Extra', X_extra.shape, y_extra.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IisuR3hbzv2V"
      },
      "outputs": [],
      "source": [
        "X_train[100][0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eugy0vAizv2a"
      },
      "source": [
        "Our newly cropped images now look like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-QjEw-uXzv2b"
      },
      "outputs": [],
      "source": [
        "# Plot a cropped image\n",
        "plt.imshow(X_train[0])\n",
        "plt.xticks([]); plt.yticks([]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKG-GAs5zv2b"
      },
      "source": [
        "### Sanity check\n",
        "\n",
        "Now that we have extracted the images and bounding box information, let's visualize the images to verify that the crops look good and that our labels still match the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6Wu_TFvczv2c"
      },
      "outputs": [],
      "source": [
        "def plot_images(images, nrows, ncols, cls_true, cls_pred=None):\n",
        "    \"\"\" Helper function for plotting nrows * ncols images\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(16, 2*nrows))\n",
        "    for i, ax in enumerate(axes.flat): \n",
        "        # Pretty string with actual label\n",
        "        true_number = ''.join(str(x) for x in cls_true[i] if x != 10)\n",
        "        if cls_pred is None:\n",
        "            title = \"True: {0}\".format(true_number)\n",
        "        else:\n",
        "            # Pretty string with predicted label\n",
        "            pred_number = ''.join(str(x) for x in cls_pred[i] if x != 10)\n",
        "            title = \"True: {0}, Pred: {1}\".format(true_number, pred_number)  \n",
        "        ax.imshow(images[i])\n",
        "        ax.set_title(title)   \n",
        "        ax.set_xticks([]); ax.set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if4xybRTzv2c"
      },
      "source": [
        "Let's plot some images from all our dataset to make sure everything looks ok!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ieXyS3B6zv2d"
      },
      "outputs": [],
      "source": [
        "# Display images from the training set\n",
        "plot_images(X_train, 3, 6, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ILoAyCWIzv2e"
      },
      "outputs": [],
      "source": [
        "# Display images from the test set\n",
        "plot_images(X_test, 3, 6, y_test);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "idG3cHfuzv2f"
      },
      "outputs": [],
      "source": [
        "# Display images from the extra set\n",
        "plot_images(X_extra, 3, 6, y_extra);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI26ZyTNzv2g"
      },
      "source": [
        "#### Scale Invariance\n",
        "\n",
        "Let's check the edge cases (1 and 5 digits) to check how much scale invariance we have introduced to our dataset through our cropping and rescaling procedure. I imagine that the crops for images with 1 digit have a fairly high height and small width causing the images to be stretched out horizontally when it is resized. The opposite might apply to images with 5 digits where our images could be stretched out vertically. However, due to the aspect ratio of the original images it is hard to get around this issue without substantial work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wIrgaiFnzv2g"
      },
      "outputs": [],
      "source": [
        "# Find some images containing 1 digit\n",
        "single_digit = (y_train != 10).sum(1) == 1\n",
        "\n",
        "# Display some exaples\n",
        "plot_images(X_train[single_digit], 4, 8, y_train[single_digit]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "T57pwGxHzv2i"
      },
      "outputs": [],
      "source": [
        "# Find some images with five digits\n",
        "#five_digits = (y_extra != 10).sum(1) == 5\n",
        "\n",
        "# Display some examples \n",
        "#plot_images(X_extra[five_digits], 4, 6, y_extra[five_digits]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bUAptiBzv2i"
      },
      "source": [
        "Let's take a closer look at sequence length distribution of our images by plotting a few histograms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "02NiwgE-zv2j"
      },
      "outputs": [],
      "source": [
        "# Initialize the subplotgrid\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, figsize=(16, 4))\n",
        "\n",
        "# Set the main figure title\n",
        "fig.suptitle('Digit Length Distribution', fontsize=14, fontweight='bold', y=1.05)\n",
        "\n",
        "# Sequence length distribution - training set \n",
        "ax1.hist((y_train != 10).sum(1), bins=5)\n",
        "ax1.set_title(\"Training set\");\n",
        "ax1.set_xlim(1, 5)\n",
        "\n",
        "# Sequence length distribution - test set \n",
        "ax2.hist((y_test != 10).sum(1), bins=5, color='g')\n",
        "ax2.set_title(\"Test set\");\n",
        "\n",
        "# Sequence length distribution - extra set \n",
        "#ax3.hist((y_extra != 10).sum(1), bins=5, color='r')\n",
        "#ax3.set_title(\"Extra set\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqN7Fgzozv2k"
      },
      "source": [
        "We can see that 1-3 digits occur most frequently while images with 4 and 5 digits are relatively rare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqF1pMUizv2m"
      },
      "source": [
        "### Creating a validation set\n",
        "\n",
        "Let's create a balanced validation set with an equal number of images with the same digit sequence lengths. The extra set is a large set of easy samples and train set is a smaller set of more difficult samples. We compose our validation set of 6000 samples with 2/3 taken from the training set and 1/3 from the extra set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "oN7NtKFvzv2m"
      },
      "outputs": [],
      "source": [
        "def random_sample(N, K):\n",
        "    \"\"\"Return a boolean mask of size N with K selections\n",
        "    \"\"\"\n",
        "    mask = np.array([True]*K + [False]*(N-K))\n",
        "    np.random.shuffle(mask)\n",
        "    return mask\n",
        "\n",
        "# Pick 4000 training and 2000 extra samples\n",
        "sample1 = random_sample(X_train.shape[0], 3000)\n",
        "#sample2 = random_sample(X_extra.shape[0], 2000)\n",
        "\n",
        "# Create valdidation from the sampled data\n",
        "#X_val = np.concatenate([X_train[sample1], X_extra[sample2]])\n",
        "#y_val = np.concatenate([y_train[sample1], y_extra[sample2]])\n",
        "X_val = X_train[sample1]\n",
        "y_val = y_train[sample1]\n",
        "\n",
        "\n",
        "# Keep the data not contained by sample\n",
        "#X_train = np.concatenate([X_train[~sample1], X_extra[~sample2]])\n",
        "#y_train = np.concatenate([y_train[~sample1], y_extra[~sample2]])\n",
        "X_train = X_train[~sample1]\n",
        "y_train = y_train[~sample1]\n",
        "\n",
        "# Moved to validation and training set\n",
        "\n",
        "\n",
        "print(\"Training\", X_train.shape, y_train.shape)\n",
        "print('Validation', X_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czn69egYzv2o"
      },
      "source": [
        "Let's examine our new datasets to make sure everything looks good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wZIveZvUzv2p"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, figsize=(16, 4))\n",
        "\n",
        "fig.suptitle('Digit Length Distribution', fontsize=14, fontweight='bold', y=1.05)\n",
        "\n",
        "ax1.hist((y_train != 10).sum(1), bins=5)\n",
        "ax1.set_title(\"Training set\");\n",
        "ax1.set_xlim(1, 5)\n",
        "\n",
        "ax2.hist((y_test != 10).sum(1), bins=5, color='g')\n",
        "ax2.set_title(\"Test set\");\n",
        "\n",
        "ax3.hist((y_val != 10).sum(1), bins=5, color='r')\n",
        "ax3.set_title(\"Validation set\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "LKwmB9Bfzv2q"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, figsize=(16, 4))\n",
        "\n",
        "fig.suptitle('Individial Digit Distribution', fontsize=14, fontweight='bold', y=1.05)\n",
        "\n",
        "ax1.hist(y_train.flatten(), bins=5)\n",
        "ax1.set_title(\"Training set\");\n",
        "ax1.set_xlim(0, 9)\n",
        "\n",
        "ax2.hist(y_test.flatten(), bins=5, color='g')\n",
        "ax2.set_title(\"Test set\");\n",
        "\n",
        "ax3.hist(y_val.flatten(), bins=5, color='r')\n",
        "ax3.set_title(\"Validation set\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mylkc6Wwzv2q"
      },
      "source": [
        "### Storing the Data\n",
        "\n",
        "Let's store our RGB images before converting them to greyscale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "w7tj_zqGzv2r"
      },
      "outputs": [],
      "source": [
        "# Create file\n",
        "h5f = h5py.File('data/SVHN_multi.h5', 'w')\n",
        "\n",
        "# Store the datasets\n",
        "h5f.create_dataset('train_dataset', data=X_train)\n",
        "h5f.create_dataset('train_labels', data=y_train)\n",
        "h5f.create_dataset('test_dataset', data=X_test)\n",
        "h5f.create_dataset('test_labels', data=y_test)\n",
        "h5f.create_dataset('valid_dataset', data=X_val)\n",
        "h5f.create_dataset('valid_labels', data=y_val)\n",
        "\n",
        "# Close the file\n",
        "h5f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwUrS5-yzv2s"
      },
      "source": [
        "Let's convert our images to greyscale and store another copy. To convert RBG values to grayscale we can take a weighted sum of the R, G, and B components. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xa0it-dBzv2t"
      },
      "outputs": [],
      "source": [
        "def rgb2gray(images):\n",
        "    \"\"\"Convert images from rbg to grayscale\n",
        "    \"\"\"\n",
        "    greyscale = np.dot(images, [0.2989, 0.5870, 0.1140])\n",
        "    return np.expand_dims(greyscale, axis=3)\n",
        "\n",
        "\n",
        "# Transform the images to greyscale\n",
        "X_train = rgb2gray(X_train).astype(np.float32)\n",
        "X_test = rgb2gray(X_test).astype(np.float32)\n",
        "X_val = rgb2gray(X_val).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYPKC5MGzv2t"
      },
      "source": [
        "Now that our images have been converted to greyscale, let's store them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zbeCnXIszv2u"
      },
      "outputs": [],
      "source": [
        "# Create file\n",
        "h5f = h5py.File('data/SVHN_multi_grey.h5', 'w')\n",
        "\n",
        "# Store the datasets\n",
        "h5f.create_dataset('train_dataset', data=X_train)\n",
        "h5f.create_dataset('train_labels', data=y_train)\n",
        "h5f.create_dataset('test_dataset', data=X_test)\n",
        "h5f.create_dataset('test_labels', data=y_test)\n",
        "h5f.create_dataset('valid_dataset', data=X_val)\n",
        "h5f.create_dataset('valid_labels', data=y_val)\n",
        "\n",
        "# Close the file\n",
        "h5f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnezUfYjzv2w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}